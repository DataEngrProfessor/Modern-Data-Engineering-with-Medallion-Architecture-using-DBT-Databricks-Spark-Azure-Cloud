# Modern Data Engineering with Medallion Architecture using DBT, Databricks, Spark and Azure Cloud 
In this project, we setup and end to end data engineering using Apache Spark, Azure Databricks, Data Build Tool (DBT) using Azure as our cloud provider. This project illustrate the process of data ingestion to the lakehouse, data integration with ADF and data transformation with Databricks, and DBT.


## System Architecture
![System Architecture.jpeg](System%20Architecture.jpeg)

## Commands
Try running the following commands:
- dbt run # for running models
- dbt test # for tests
- dbt snapshot # for snapshotting and slowly changing dimensions
- dbt docs generate # for documentation
- dbt docs serve # for documentation preview


## Resources:
* [Medium Article](https://medium.com/@yusuf.ganiyu/robust-data-pipelines-with-databricks-spark-dbt-and-azure-data-engineering-project-e5780fbc07a6)
* [DBT](https://docs.getdbt.com/guides)
* [Databricks](https://docs.databricks.com/)
* [Azure](https://docs.microsoft.com/en-us/azure/?product=featured)
* [Azure Data Factory](https://docs.microsoft.com/en-us/azure/data-factory/)
* [Azure Data Lake Storage Gen2](https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction)

### Youtube Video
[![Modern Data Engienering](https://img.youtube.com/vi/divjURi-low/0.jpg)](https://youtu.be/divjURi-low)

